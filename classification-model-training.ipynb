{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# GPU Configuration\ndef setup_device():\n    \"\"\"Setup and display GPU configuration\"\"\"\n    if torch.cuda.is_available():\n        num_gpus = torch.cuda.device_count()\n        print(f\"Number of GPUs available: {num_gpus}\")\n        \n        for i in range(num_gpus):\n            gpu_name = torch.cuda.get_device_name(i)\n            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n            print(f\"GPU {i}: {gpu_name}, Memory: {gpu_memory:.2f} GB\")\n        \n        if num_gpus > 1:\n            print(f\"\\n✓ Using DataParallel with {num_gpus} GPUs for faster training!\")\n            device = torch.device(\"cuda\")\n        else:\n            print(\"\\n✓ Using single GPU\")\n            device = torch.device(\"cuda\")\n    else:\n        print(\"No GPU available, using CPU\")\n        device = torch.device(\"cpu\")\n    \n    return device, num_gpus if torch.cuda.is_available() else 0\n\ndevice, num_gpus = setup_device()\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)  # Set seed for all GPUs\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Configuration\nclass Config:\n    # Paths - Update this path based on your Kaggle dataset location\n    data_dir = '/kaggle/input/labeled-mri-brain-tumor-dataset/Brain Tumor labeled dataset'\n    \n    # Hyperparameters (adjusted for multi-GPU)\n    base_batch_size = 32  # Batch size per GPU\n    batch_size = base_batch_size * max(1, num_gpus)  # Total batch size\n    num_epochs = 25\n    base_learning_rate = 0.001\n    learning_rate = base_learning_rate * max(1, num_gpus)  # Linear scaling rule\n    num_workers = 4 * max(1, num_gpus)  # More workers for multi-GPU\n    \n    # Model\n    model_name = 'resnet101'  # Can be 'resnet18', 'resnet34', 'resnet50', 'resnet101'\n    pretrained = True\n    freeze_backbone = False  # Set to True to freeze early layers\n    \n    # Data split\n    train_split = 0.8\n    val_split = 0.1\n    test_split = 0.1\n    \n    # Image settings\n    img_size = 224\n    \n    # Training settings\n    gradient_accumulation_steps = 1\n    mixed_precision = True  # Use mixed precision training for faster computation\n    \nconfig = Config()\n\nprint(f\"\\nTraining Configuration:\")\nprint(f\"Total Batch Size: {config.batch_size}\")\nprint(f\"Learning Rate: {config.learning_rate}\")\nprint(f\"Number of Workers: {config.num_workers}\")\nprint(f\"Mixed Precision Training: {config.mixed_precision}\")\n\n# Data Transforms\ndef get_transforms():\n    \"\"\"Get data transformation pipelines\"\"\"\n    \n    train_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    val_test_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    return train_transform, val_test_transform\n\n# Load Dataset\ndef load_data():\n    \"\"\"Load and split the dataset\"\"\"\n    \n    train_transform, val_test_transform = get_transforms()\n    \n    # Load the full dataset\n    full_dataset = datasets.ImageFolder(root=config.data_dir, transform=train_transform)\n    \n    # Get class names\n    class_names = full_dataset.classes\n    num_classes = len(class_names)\n    print(f\"\\nDataset Information:\")\n    print(f\"Classes: {class_names}\")\n    print(f\"Number of classes: {num_classes}\")\n    \n    # Calculate split sizes\n    total_size = len(full_dataset)\n    train_size = int(config.train_split * total_size)\n    val_size = int(config.val_split * total_size)\n    test_size = total_size - train_size - val_size\n    \n    # Random split\n    train_dataset, val_dataset, test_dataset = random_split(\n        full_dataset, [train_size, val_size, test_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    # Update transforms for validation and test sets\n    val_dataset.dataset.transform = val_test_transform\n    test_dataset.dataset.transform = val_test_transform\n    \n    # Create data loaders with optimized settings for multi-GPU\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=config.batch_size, \n        shuffle=True, \n        num_workers=config.num_workers,\n        pin_memory=True,\n        persistent_workers=True if config.num_workers > 0 else False,\n        prefetch_factor=2\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=config.batch_size, \n        shuffle=False, \n        num_workers=config.num_workers,\n        pin_memory=True,\n        persistent_workers=True if config.num_workers > 0 else False,\n        prefetch_factor=2\n    )\n    \n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=config.batch_size, \n        shuffle=False, \n        num_workers=config.num_workers,\n        pin_memory=True,\n        persistent_workers=True if config.num_workers > 0 else False,\n        prefetch_factor=2\n    )\n    \n    print(f\"Dataset sizes - Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n    \n    return train_loader, val_loader, test_loader, class_names, num_classes\n\n# Create Model\ndef create_model(num_classes):\n    \"\"\"Create and configure the ResNet model with multi-GPU support\"\"\"\n    \n    # Select ResNet architecture\n    model_dict = {\n        'resnet18': models.resnet18,\n        'resnet34': models.resnet34,\n        'resnet50': models.resnet50,\n        'resnet101': models.resnet101,\n    }\n    \n    # Load pretrained model\n    model = model_dict[config.model_name](pretrained=config.pretrained)\n    \n    # Freeze backbone layers if specified\n    if config.freeze_backbone:\n        for param in model.parameters():\n            param.requires_grad = False\n    \n    # Modify the final fully connected layer\n    num_features = model.fc.in_features\n    model.fc = nn.Sequential(\n        nn.Dropout(0.5),\n        nn.Linear(num_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, num_classes)\n    )\n    \n    # Move model to device\n    model = model.to(device)\n    \n    # Wrap model with DataParallel for multi-GPU training\n    if num_gpus > 1:\n        model = nn.DataParallel(model)\n        print(f\"\\n✓ Model wrapped with DataParallel for {num_gpus} GPUs\")\n    \n    return model\n\n# Mixed Precision Training Setup\nscaler = torch.cuda.amp.GradScaler() if config.mixed_precision and torch.cuda.is_available() else None\n\n# Training function with multi-GPU optimization\ndef train_epoch(model, dataloader, criterion, optimizer):\n    \"\"\"Train the model for one epoch with multi-GPU support\"\"\"\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    progress_bar = tqdm(dataloader, desc='Training')\n    for batch_idx, (images, labels) in enumerate(progress_bar):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        \n        # Mixed precision training\n        if config.mixed_precision and scaler is not None:\n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss = loss / config.gradient_accumulation_steps\n            \n            scaler.scale(loss).backward()\n            \n            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n        else:\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss = loss / config.gradient_accumulation_steps\n            loss.backward()\n            \n            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n        \n        # Statistics\n        running_loss += loss.item() * config.gradient_accumulation_steps\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Update progress bar\n        progress_bar.set_postfix({\n            'loss': loss.item() * config.gradient_accumulation_steps,\n            'acc': 100. * correct / total,\n            'gpu_mem': f'{torch.cuda.memory_allocated()/1e9:.2f}GB' if torch.cuda.is_available() else 'N/A'\n        })\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = 100. * correct / total\n    \n    return epoch_loss, epoch_acc\n\n# Validation function with multi-GPU support\ndef validate(model, dataloader, criterion):\n    \"\"\"Validate the model\"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc='Validation'):\n            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n            \n            if config.mixed_precision and torch.cuda.is_available():\n                with torch.cuda.amp.autocast():\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n            else:\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            # Statistics\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = 100. * correct / total\n    \n    return epoch_loss, epoch_acc, all_predictions, all_labels\n\n# Training loop with learning rate warmup for multi-GPU\ndef train_model(model, train_loader, val_loader, num_epochs):\n    \"\"\"Main training loop with multi-GPU optimizations\"\"\"\n    \n    # Loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    \n    # Use different optimizer for better multi-GPU training\n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0.01)\n    \n    # Learning rate scheduler with warmup\n    warmup_epochs = 3\n    scheduler = optim.lr_scheduler.OneCycleLR(\n        optimizer, \n        max_lr=config.learning_rate,\n        epochs=num_epochs,\n        steps_per_epoch=len(train_loader),\n        pct_start=warmup_epochs/num_epochs,\n        anneal_strategy='cos'\n    )\n    \n    # Training history\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': []\n    }\n    \n    best_val_acc = 0.0\n    best_model_state = None\n    \n    print(f\"\\nStarting training on {num_gpus if num_gpus > 0 else 1} device(s)...\")\n    print(\"=\"*60)\n    \n    for epoch in range(num_epochs):\n        print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n        print('-' * 60)\n        \n        # Train\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n        \n        # Step scheduler after each batch (already done in train_epoch for OneCycleLR)\n        if isinstance(scheduler, optim.lr_scheduler.OneCycleLR):\n            pass  # OneCycleLR steps are handled in train_epoch\n        else:\n            scheduler.step()\n        \n        # Validate\n        val_loss, val_acc, _, _ = validate(model, val_loader, criterion)\n        \n        # Save history\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        # Print metrics\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n        print(f'Learning Rate: {current_lr:.6f}')\n        \n        if torch.cuda.is_available():\n            for i in range(num_gpus):\n                memory_allocated = torch.cuda.memory_allocated(i) / 1e9\n                memory_reserved = torch.cuda.memory_reserved(i) / 1e9\n                print(f'GPU {i} - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB')\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            # Handle DataParallel when saving\n            if isinstance(model, nn.DataParallel):\n                best_model_state = model.module.state_dict().copy()\n            else:\n                best_model_state = model.state_dict().copy()\n            print(f'✓ Best model saved with validation accuracy: {best_val_acc:.2f}%')\n        \n        # Clear cache to free memory\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    # Load best model\n    if best_model_state is not None:\n        if isinstance(model, nn.DataParallel):\n            model.module.load_state_dict(best_model_state)\n        else:\n            model.load_state_dict(best_model_state)\n    \n    return model, history\n\n# Visualization functions\ndef plot_training_history(history):\n    \"\"\"Plot training history\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # Loss plot\n    ax1.plot(history['train_loss'], label='Train Loss', linewidth=2)\n    ax1.plot(history['val_loss'], label='Validation Loss', linewidth=2)\n    ax1.set_xlabel('Epoch', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.set_title('Training and Validation Loss', fontsize=14)\n    ax1.legend(fontsize=11)\n    ax1.grid(True, alpha=0.3)\n    \n    # Accuracy plot\n    ax2.plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n    ax2.plot(history['val_acc'], label='Validation Accuracy', linewidth=2)\n    ax2.set_xlabel('Epoch', fontsize=12)\n    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n    ax2.set_title('Training and Validation Accuracy', fontsize=14)\n    ax2.legend(fontsize=11)\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, class_names):\n    \"\"\"Plot confusion matrix\"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names,\n                cbar_kws={'label': 'Count'})\n    plt.title('Confusion Matrix', fontsize=16)\n    plt.xlabel('Predicted Label', fontsize=12)\n    plt.ylabel('True Label', fontsize=12)\n    plt.show()\n\n# Test function\ndef test_model(model, test_loader, class_names):\n    \"\"\"Test the model and display results\"\"\"\n    criterion = nn.CrossEntropyLoss()\n    \n    print(\"\\nEvaluating on test set...\")\n    test_loss, test_acc, predictions, labels = validate(model, test_loader, criterion)\n    \n    print(f'\\nTest Loss: {test_loss:.4f}')\n    print(f'Test Accuracy: {test_acc:.2f}%')\n    \n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(\"=\"*60)\n    print(classification_report(labels, predictions, target_names=class_names))\n    \n    # Confusion matrix\n    plot_confusion_matrix(labels, predictions, class_names)\n    \n    return test_acc\n\n# Display sample predictions\ndef display_sample_predictions(model, test_loader, class_names, num_samples=8):\n    \"\"\"Display sample predictions from the test set\"\"\"\n    model.eval()\n    images, labels = next(iter(test_loader))\n    images, labels = images[:num_samples].to(device), labels[:num_samples]\n    \n    with torch.no_grad():\n        if config.mixed_precision and torch.cuda.is_available():\n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n        else:\n            outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n    \n    # Denormalize images for display\n    def denormalize(tensor):\n        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n        return tensor * std + mean\n    \n    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n    axes = axes.ravel()\n    \n    for idx in range(num_samples):\n        img = denormalize(images[idx].cpu())\n        img = np.transpose(img.numpy(), (1, 2, 0))\n        img = np.clip(img, 0, 1)\n        \n        axes[idx].imshow(img)\n        axes[idx].set_title(f'True: {class_names[labels[idx]]}\\nPred: {class_names[predicted[idx]]}',\n                           color='green' if labels[idx] == predicted[idx] else 'red')\n        axes[idx].axis('off')\n    \n    plt.suptitle('Sample Predictions', fontsize=16)\n    plt.tight_layout()\n    plt.show()\n\n# Main execution\ndef main():\n    \"\"\"Main execution function\"\"\"\n    \n    # Load data\n    train_loader, val_loader, test_loader, class_names, num_classes = load_data()\n    \n    # Create model\n    model = create_model(num_classes)\n    \n    # Model information\n    if isinstance(model, nn.DataParallel):\n        total_params = sum(p.numel() for p in model.module.parameters())\n        trainable_params = sum(p.numel() for p in model.module.parameters() if p.requires_grad)\n    else:\n        total_params = sum(p.numel() for p in model.parameters())\n        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"\\nModel: {config.model_name}\")\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    # Train model\n    model, history = train_model(model, train_loader, val_loader, config.num_epochs)\n    \n    # Plot training history\n    plot_training_history(history)\n    \n    # Test model\n    test_accuracy = test_model(model, test_loader, class_names)\n    \n    # Display sample predictions\n    display_sample_predictions(model, test_loader, class_names)\n    \n    # Save model\n    model_path = f'{config.model_name}_brain_tumor_classifier_multigpu.pth'\n    \n    # Handle DataParallel when saving\n    if isinstance(model, nn.DataParallel):\n        model_to_save = model.module\n    else:\n        model_to_save = model\n    \n    torch.save({\n        'model_state_dict': model_to_save.state_dict(),\n        'class_names': class_names,\n        'test_accuracy': test_accuracy,\n        'config': config.__dict__,\n        'num_gpus_trained': num_gpus\n    }, model_path)\n    \n    print(f\"\\nModel saved to {model_path}\")\n    print(f\"Training completed using {num_gpus} GPU(s)!\")\n    \n    return model, history, test_accuracy\n\n# Run the training\nif __name__ == \"__main__\":\n    model, history, test_accuracy = main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}